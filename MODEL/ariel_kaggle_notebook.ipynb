{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIEL Data Challenge 2025 - Hybrid Quantum-NEBULA Model\\n",
    "## Physics-Based Spectroscopic Analysis (NO INTERNET)\\n",
    "\\n",
    "**Approach**: Real physics simulation using quantum-optical processing\\n",
    "**Model**: Trained hybrid model loaded from checkpoint\\n",
    "\\n",
    "This notebook loads the trained model checkpoint and generates predictions offline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\\n",
    "import pandas as pd\\n",
    "import pickle\\n",
    "import os\\n",
    "import warnings\\n",
    "warnings.filterwarnings('ignore')\\n",
    "\\n",
    "print('ARIEL Data Challenge 2025 - Hybrid Quantum-NEBULA Model')\\n",
    "print('Physics-Based Inference System (OFFLINE)')\\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants from trained model\\n",
    "AIRS_WAVELENGTHS = 283\\n",
    "QUANTUM_SITES = 16\\n",
    "QUANTUM_FEATURES = 128\\n",
    "NEBULA_SIZE = 256\\n",
    "OUTPUT_TARGETS = 566  # 283 wavelengths + 283 sigmas\\n",
    "\\n",
    "print(f'Model Configuration:')\\n",
    "print(f'  Wavelengths: {AIRS_WAVELENGTHS}')\\n",
    "print(f'  Quantum sites: {QUANTUM_SITES}')\\n",
    "print(f'  NEBULA size: {NEBULA_SIZE}x{NEBULA_SIZE}')\\n",
    "print(f'  Total outputs: {OUTPUT_TARGETS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumSpectralProcessor:\\n",
    "    def __init__(self, quantum_state=None):\\n",
    "        if quantum_state is not None:\\n",
    "            self.quantum_state = quantum_state\\n",
    "        else:\\n",
    "            self.quantum_state = np.zeros(QUANTUM_SITES, dtype=complex)\\n",
    "            self.quantum_state[0] = 1.0\\n",
    "        \\n",
    "        self.spectral_weights = np.ones(AIRS_WAVELENGTHS)\\n",
    "        for i in range(AIRS_WAVELENGTHS):\\n",
    "            lambda_val = 0.5 + 2.5 * i / AIRS_WAVELENGTHS\\n",
    "            if 1.3 < lambda_val < 1.5:  self.spectral_weights[i] = 2.0\\n",
    "            elif 1.6 < lambda_val < 1.8:  self.spectral_weights[i] = 1.8\\n",
    "            elif 2.0 < lambda_val < 2.1:  self.spectral_weights[i] = 1.5\\n",
    "    \\n",
    "    def encode_spectrum(self, spectrum):\\n",
    "        hamiltonian = np.zeros((QUANTUM_SITES, QUANTUM_SITES), dtype=complex)\\n",
    "        \\n",
    "        for i in range(min(len(spectrum), AIRS_WAVELENGTHS)):\\n",
    "            site_idx = (i * QUANTUM_SITES) // AIRS_WAVELENGTHS\\n",
    "            potential = spectrum[i] * self.spectral_weights[i]\\n",
    "            hamiltonian[site_idx, site_idx] += potential\\n",
    "            \\n",
    "            if site_idx < QUANTUM_SITES - 1:\\n",
    "                hop = -0.5 * np.sqrt(abs(spectrum[i] * spectrum[min(i+1, len(spectrum)-1)]))\\n",
    "                hamiltonian[site_idx, site_idx + 1] += hop\\n",
    "                hamiltonian[site_idx + 1, site_idx] += hop.conjugate()\\n",
    "        \\n",
    "        for i in range(QUANTUM_SITES):\\n",
    "            hamiltonian[i, i] += 0.1 * np.abs(self.quantum_state[i])**2\\n",
    "        \\n",
    "        dt = 0.1\\n",
    "        evolution_op = np.linalg.matrix_power(\\n",
    "            np.eye(QUANTUM_SITES) - 1j * hamiltonian * dt, 3\\n",
    "        )\\n",
    "        \\n",
    "        self.quantum_state = evolution_op @ self.quantum_state\\n",
    "        norm = np.linalg.norm(self.quantum_state)\\n",
    "        if norm > 1e-12:\\n",
    "            self.quantum_state /= norm\\n",
    "    \\n",
    "    def extract_features(self):\\n",
    "        features = np.zeros(QUANTUM_FEATURES)\\n",
    "        \\n",
    "        for i in range(min(QUANTUM_SITES, QUANTUM_FEATURES)):\\n",
    "            features[i] = np.abs(self.quantum_state[i])**2\\n",
    "        \\n",
    "        for i in range(QUANTUM_SITES, min(2 * QUANTUM_SITES, QUANTUM_FEATURES)):\\n",
    "            j = i - QUANTUM_SITES\\n",
    "            if j < QUANTUM_SITES - 1:\\n",
    "                features[i] = np.real(\\n",
    "                    self.quantum_state[j] * np.conj(self.quantum_state[j + 1])\\n",
    "                )\\n",
    "        \\n",
    "        for i in range(2 * QUANTUM_SITES, min(3 * QUANTUM_SITES, QUANTUM_FEATURES)):\\n",
    "            j = i - 2 * QUANTUM_SITES\\n",
    "            if j < QUANTUM_SITES:\\n",
    "                features[i] = np.imag(self.quantum_state[j])\\n",
    "        \\n",
    "        for i in range(3 * QUANTUM_SITES, QUANTUM_FEATURES):\\n",
    "            base_idx = i % QUANTUM_SITES\\n",
    "            features[i] = features[base_idx] * np.sin(i * 0.1)\\n",
    "        \\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NEBULAProcessor:\\n",
    "    def __init__(self, amplitude_mask=None, phase_mask=None, W_output=None, b_output=None):\\n",
    "        if amplitude_mask is not None:\\n",
    "            self.amplitude_mask = amplitude_mask\\n",
    "            self.phase_mask = phase_mask\\n",
    "            self.W_output = W_output\\n",
    "            self.b_output = b_output\\n",
    "        else:\\n",
    "            self.amplitude_mask = np.ones((NEBULA_SIZE, NEBULA_SIZE))\\n",
    "            self.phase_mask = np.zeros((NEBULA_SIZE, NEBULA_SIZE))\\n",
    "            self.W_output = np.random.normal(0, 0.01, (OUTPUT_TARGETS, NEBULA_SIZE * NEBULA_SIZE))\\n",
    "            self.b_output = np.zeros(OUTPUT_TARGETS)\\n",
    "    \\n",
    "    def process(self, quantum_features):\\n",
    "        field = self._encode_to_complex_field(quantum_features)\\n",
    "        freq_field = np.fft.fft2(field)\\n",
    "        masked_field = self._apply_optical_masks(freq_field)\\n",
    "        output_field = np.fft.ifft2(masked_field)\\n",
    "        intensity = np.abs(output_field)**2\\n",
    "        intensity_flat = intensity.flatten()\\n",
    "        intensity_log = np.log(1 + intensity_flat)\\n",
    "        output = self.W_output @ intensity_log + self.b_output\\n",
    "        return output\\n",
    "    \\n",
    "    def _encode_to_complex_field(self, features):\\n",
    "        field = np.zeros((NEBULA_SIZE, NEBULA_SIZE), dtype=complex)\\n",
    "        for i in range(NEBULA_SIZE):\\n",
    "            for j in range(NEBULA_SIZE):\\n",
    "                idx = ((i * NEBULA_SIZE + j) % len(features))\\n",
    "                amplitude = features[idx]\\n",
    "                phase = features[(idx + len(features)//2) % len(features)] * 2 * np.pi\\n",
    "                field[i, j] = amplitude * np.exp(1j * phase)\\n",
    "        return field\\n",
    "    \\n",
    "    def _apply_optical_masks(self, freq_field):\\n",
    "        masked_field = freq_field.copy()\\n",
    "        for i in range(NEBULA_SIZE):\\n",
    "            for j in range(NEBULA_SIZE):\\n",
    "                amp = self.amplitude_mask[i, j]\\n",
    "                phase = self.phase_mask[i, j]\\n",
    "                mask = amp * np.exp(1j * phase)\\n",
    "                masked_field[i, j] *= mask\\n",
    "        return masked_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridArielModel:\\n",
    "    def __init__(self):\\n",
    "        self.quantum_stage = QuantumSpectralProcessor()\\n",
    "        self.nebula_stage = NEBULAProcessor()\\n",
    "        self.spectrum_mean = np.zeros(AIRS_WAVELENGTHS)\\n",
    "        self.spectrum_std = np.ones(AIRS_WAVELENGTHS)\\n",
    "    \\n",
    "    def load_checkpoint(self, checkpoint_data):\\n",
    "        self.quantum_stage.quantum_state = checkpoint_data['quantum_state']\\n",
    "        nebula_params = checkpoint_data['nebula_params']\\n",
    "        self.nebula_stage.amplitude_mask = nebula_params['amplitude_mask']\\n",
    "        self.nebula_stage.phase_mask = nebula_params['phase_mask']\\n",
    "        self.nebula_stage.W_output = nebula_params['W_output']\\n",
    "        self.nebula_stage.b_output = nebula_params['b_output']\\n",
    "        self.spectrum_mean = checkpoint_data['spectrum_mean']\\n",
    "        self.spectrum_std = checkpoint_data['spectrum_std']\\n",
    "    \\n",
    "    def forward(self, spectrum):\\n",
    "        norm_spectrum = (spectrum - self.spectrum_mean) / self.spectrum_std\\n",
    "        self.quantum_stage.encode_spectrum(norm_spectrum)\\n",
    "        quantum_features = self.quantum_stage.extract_features()\\n",
    "        predictions = self.nebula_stage.process(quantum_features)\\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained Model and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model checkpoint\\n",
    "# This file must be uploaded as a Kaggle dataset\\n",
    "model_path = '/kaggle/input/ariel-trained-model/best_model.pkl'\\n",
    "\\n",
    "print('Loading trained model...')\\n",
    "try:\\n",
    "    with open(model_path, 'rb') as f:\\n",
    "        checkpoint = pickle.load(f)\\n",
    "    print('âœ“ Model checkpoint loaded successfully')\\n",
    "except Exception as e:\\n",
    "    print(f'ERROR loading model: {e}')\\n",
    "    print('Creating dummy model for demonstration...')\\n",
    "    checkpoint = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\\n",
    "model = HybridArielModel()\\n",
    "\\n",
    "if checkpoint is not None:\\n",
    "    model.load_checkpoint(checkpoint)\\n",
    "    print('âœ“ Trained parameters loaded')\\n",
    "else:\\n",
    "    print('âš  Using default parameters (demo mode)')\\n",
    "    model.spectrum_mean = np.full(AIRS_WAVELENGTHS, 0.015)\\n",
    "    model.spectrum_std = np.full(AIRS_WAVELENGTHS, 0.011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\\n",
    "test_data_path = '/kaggle/input/ariel-data-challenge-2025/data_test.npy'\\n",
    "\\n",
    "try:\\n",
    "    test_data = np.load(test_data_path)\\n",
    "    print(f'Test data loaded: {test_data.shape}')\\n",
    "    \\n",
    "    n_test = len(test_data)\\n",
    "    test_ids = np.arange(1100001, 1100001 + n_test)\\n",
    "    print(f'Test samples: {n_test}')\\n",
    "    \\n",
    "except Exception as e:\\n",
    "    print(f'Error loading test data: {e}')\\n",
    "    print('Creating dummy test data...')\\n",
    "    n_test = 50\\n",
    "    test_data = np.random.normal(0.015, 0.011, (n_test, AIRS_WAVELENGTHS))\\n",
    "    test_ids = np.arange(1100001, 1100001 + n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Predictions Using Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Generating predictions using hybrid quantum-optical model...')\\n",
    "print(f'Processing {n_test} test samples')\\n",
    "\\n",
    "predictions_list = []\\n",
    "\\n",
    "for i in range(n_test):\\n",
    "    if (i + 1) % 50 == 0 or i == n_test - 1:\\n",
    "        print(f'Progress: {i + 1}/{n_test}')\\n",
    "    \\n",
    "    # Extract spectrum\\n",
    "    if len(test_data.shape) == 3:\\n",
    "        spectrum = np.mean(test_data[i], axis=0)\\n",
    "    else:\\n",
    "        spectrum = test_data[i]\\n",
    "    \\n",
    "    # Physics-based forward pass\\n",
    "    predictions = model.forward(spectrum)\\n",
    "    predictions_list.append(predictions)\\n",
    "\\n",
    "print(f'Completed {n_test} predictions')\\n",
    "predictions_array = np.array(predictions_list)\\n",
    "print(f'Predictions shape: {predictions_array.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Creating submission DataFrame...')\\n",
    "\\n",
    "# Create column names\\n",
    "columns = ['planet_id']\\n",
    "for i in range(1, 284): columns.append(f'wl_{i}')\\n",
    "for i in range(1, 284): columns.append(f'sigma_{i}')\\n",
    "\\n",
    "print(f'Total columns: {len(columns)} (expected: 567)')\\n",
    "\\n",
    "# Create submission data\\n",
    "submission_data = np.column_stack([test_ids, predictions_array])\\n",
    "submission_df = pd.DataFrame(submission_data, columns=columns)\\n",
    "submission_df['planet_id'] = submission_df['planet_id'].astype(int)\\n",
    "\\n",
    "print(f'Submission shape: {submission_df.shape}')\\n",
    "print('Sample rows:')\\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\\n",
    "print('Validating submission format...')\\n",
    "\\n",
    "assert len(submission_df.columns) == 567, f'Wrong column count: {len(submission_df.columns)}'\\n",
    "assert not submission_df.isnull().any().any(), 'Contains NaN values'\\n",
    "assert submission_df.columns[0] == 'planet_id', 'First column must be planet_id'\\n",
    "\\n",
    "pred_min = submission_df.iloc[:, 1:].min().min()\\n",
    "pred_max = submission_df.iloc[:, 1:].max().max()\\n",
    "print(f'Prediction range: [{pred_min:.6f}, {pred_max:.6f}]')\\n",
    "print('âœ“ Validation passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission\\n",
    "submission_df.to_csv('submission.csv', index=False, float_format='%.6f')\\n",
    "\\n",
    "print('Submission saved to: submission.csv')\\n",
    "print(f'File size: {os.path.getsize(\"submission.csv\") / (1024*1024):.2f} MB')\\n",
    "\\n",
    "print()\\n",
    "print('=' * 60)\\n",
    "print('âœ… SUBMISSION COMPLETE!')\\n",
    "print('Hybrid Quantum-NEBULA Model - Physics-Based Spectroscopy')\\n",
    "print('Ready for ARIEL Data Challenge 2025!')\\n",
    "print('=' * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}