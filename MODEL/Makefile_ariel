# Makefile for Hybrid Quantum-NEBULA Ariel Model
# Requires: CUDA, ITensor, cnpy, BLAS/LAPACK

# Compiler settings
CXX = g++
NVCC = nvcc
CXXFLAGS = -std=c++17 -O3 -march=native -fopenmp
NVCCFLAGS = -std=c++14 -O3 -arch=sm_70 --use_fast_math

# Paths (adjust for your system)
CUDA_PATH = /usr/local/cuda
ITENSOR_PATH = $(HOME)/itensor
CNPY_PATH = $(HOME)/cnpy

# Include directories
INCLUDES = -I$(CUDA_PATH)/include \
           -I$(ITENSOR_PATH) \
           -I$(CNPY_PATH) \
           -I.

# Library directories
LIB_DIRS = -L$(CUDA_PATH)/lib64 \
           -L$(ITENSOR_PATH)/lib \
           -L$(CNPY_PATH)

# Libraries
LIBS = -lcudart -lcufft -lcublas \
       -litensor -lblas -llapack \
       -lcnpy -lz \
       -lpthread -lm

# Source files
SOURCES = ariel_trainer.cpp
CUDA_SOURCES = nebula_kernels.cu

# Object files
OBJECTS = $(SOURCES:.cpp=.o)
CUDA_OBJECTS = $(CUDA_SOURCES:.cu=.o)

# Headers
HEADERS = hybrid_ariel_model.hpp \
          ariel_data_loader.hpp

# Target executable
TARGET = ariel_trainer

# Build rules
all: $(TARGET)

$(TARGET): $(OBJECTS) $(CUDA_OBJECTS)
	$(CXX) $(CXXFLAGS) $(INCLUDES) -o $@ $^ $(LIB_DIRS) $(LIBS)

%.o: %.cpp $(HEADERS)
	$(CXX) $(CXXFLAGS) $(INCLUDES) -c $< -o $@

%.o: %.cu
	$(NVCC) $(NVCCFLAGS) $(INCLUDES) -c $< -o $@

# Create NEBULA CUDA kernels file
nebula_kernels.cu:
	@echo "Creating NEBULA CUDA kernels..."
	@cat > nebula_kernels.cu << 'EOF'
#include <cuda_runtime.h>
#include <cufft.h>

__global__ void encodeToComplexField(float* input, cufftComplex* field, 
                                     int input_size, int field_dim) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if(idx < field_dim * field_dim) {
        int input_idx = idx % input_size;
        field[idx].x = input[input_idx] * cosf(idx * 0.1f);
        field[idx].y = input[input_idx] * sinf(idx * 0.1f);
    }
}

__global__ void applyOpticalMasks(cufftComplex* freq, float* amp_mask, 
                                  float* phase_mask, int dim) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if(idx < dim * dim) {
        float amp = amp_mask[idx];
        float phase = phase_mask[idx];
        
        float real = freq[idx].x * amp * cosf(phase) - 
                    freq[idx].y * amp * sinf(phase);
        float imag = freq[idx].x * amp * sinf(phase) + 
                    freq[idx].y * amp * cosf(phase);
        
        freq[idx].x = real;
        freq[idx].y = imag;
    }
}

__global__ void calculateIntensity(cufftComplex* field, float* intensity, int dim) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if(idx < dim * dim) {
        float norm = 1.0f / (dim * dim);
        intensity[idx] = (field[idx].x * field[idx].x + 
                         field[idx].y * field[idx].y) * norm;
    }
}

__global__ void computeOutput(float* intensity, float* W, float* b, 
                              float* output, int input_dim, int output_dim) {
    int out_idx = blockIdx.x * blockDim.x + threadIdx.x;
    if(out_idx < output_dim) {
        float sum = b[out_idx];
        for(int i = 0; i < input_dim; ++i) {
            sum += W[out_idx * input_dim + i] * logf(1.0f + intensity[i]);
        }
        output[out_idx] = sum;
    }
}

__global__ void updateOutputLayer(float* W, float* b, float* grad, 
                                 float lr, int out_dim, int in_dim) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if(idx < out_dim * in_dim) {
        W[idx] -= lr * grad[idx % out_dim];
    }
    if(idx < out_dim) {
        b[idx] -= lr * grad[idx];
    }
}
EOF

# Clean build
clean:
	rm -f $(OBJECTS) $(CUDA_OBJECTS) $(TARGET) nebula_kernels.cu
	rm -rf outputs/

# Install dependencies
install-deps:
	@echo "Installing dependencies..."
	@echo "1. ITensor:"
	@echo "   git clone https://github.com/ITensor/ITensor ~/itensor"
	@echo "   cd ~/itensor && make"
	@echo ""
	@echo "2. cnpy (numpy loader for C++):"
	@echo "   git clone https://github.com/rogersce/cnpy ~/cnpy"
	@echo "   cd ~/cnpy && cmake . && make"
	@echo ""
	@echo "3. CUDA Toolkit:"
	@echo "   Download from https://developer.nvidia.com/cuda-toolkit"
	@echo ""
	@echo "4. BLAS/LAPACK:"
	@echo "   sudo apt-get install libblas-dev liblapack-dev"

# Run training
train: $(TARGET)
	./$(TARGET) --data "E:/NeurIPS_MYCELIUM_EVOLUTUM/ariel-data-challenge-2025" \
	            --epochs 100 \
	            --batch 32 \
	            --lr 0.001 \
	            --output ./outputs

# Quick test run
test: $(TARGET)
	./$(TARGET) --data "E:/NeurIPS_MYCELIUM_EVOLUTUM/ariel-data-challenge-2025" \
	            --epochs 1 \
	            --batch 8 \
	            --lr 0.001 \
	            --output ./test_outputs

# Generate submission
submit: $(TARGET)
	@echo "Generating Kaggle submission..."
	./$(TARGET) --data "E:/NeurIPS_MYCELIUM_EVOLUTUM/ariel-data-challenge-2025" \
	            --epochs 0 \
	            --output ./submission
	@echo "Submission ready at: ./submission/kaggle_submission.csv"

# Profile with nvprof
profile: $(TARGET)
	nvprof --print-gpu-trace ./$(TARGET) --epochs 1 --batch 4

# Help
help:
	@echo "Hybrid Quantum-NEBULA Model for Ariel Data Challenge 2025"
	@echo ""
	@echo "Usage:"
	@echo "  make            - Build the model"
	@echo "  make train      - Train on full dataset"
	@echo "  make test       - Quick test run"
	@echo "  make submit     - Generate Kaggle submission"
	@echo "  make clean      - Clean build files"
	@echo "  make install-deps - Show dependency installation instructions"
	@echo ""
	@echo "Training options:"
	@echo "  ./ariel_trainer --data <path> --epochs <n> --batch <n> --lr <f>"

.PHONY: all clean install-deps train test submit profile help nebula_kernels.cu
